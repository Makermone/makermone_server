import streamlit as st
import requests
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv

load_dotenv() 
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# --- 2. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ë©”ì´ì»¤ëª¬ PM í¬í„¸", page_icon="ğŸ¤–", layout="wide")

# [ì™„ë²½ ìœ„ì¥ìˆ ] Streamlit ê¸°ë³¸ ë©”ë‰´, í—¤ë”, í‘¸í„° ì™„ì „íˆ ìˆ¨ê¸°ê¸°
hide_st_style = """
            <style>
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            </style>
            """
st.markdown(hide_st_style, unsafe_allow_html=True)

# ... (ì´í•˜ ê¸°ì¡´ ì½”ë“œ ë™ì¼)
if not GOOGLE_API_KEY:
    st.error("ğŸš¨ í™˜ê²½ ë³€ìˆ˜ì— GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.stop()

client_code = st.query_params.get("client_code")

if not client_code:
    st.warning("âš ï¸ URLì— ê³ ê°ì‚¬ ëª…ì°°ì´ ì—†ìŠµë‹ˆë‹¤. ì£¼ì†Œì°½ ëì— `?client_code=JD` ë¥¼ ë¶™ì—¬ì£¼ì„¸ìš”.")
    st.stop() 

# --- 2. ë°ì´í„° ë¼ìš°í„° í˜¸ì¶œ (ìºì‹œ ì™„ì „ ì‚­ì œ!) ---
# @st.cache_data ë¶€ë¶„ì„ ì‚­ì œí•˜ì—¬, ìƒˆë¡œê³ ì¹¨ í•  ë•Œë§ˆë‹¤ ë¬´ì¡°ê±´ êµ¬ê¸€ ì‹œíŠ¸ì˜ ìµœì‹  ìƒíƒœë¥¼ í¼ì˜¤ë„ë¡ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
def get_pm_data(code):
    GAS_URL = "https://script.google.com/macros/s/AKfycbz4JTfSxbdKMILhG2X9GepP1ZiNjFu7cYTUsqIALZmtL0k3FudVkzNdwK40n7FhZavM/exec"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0"}
    response = requests.get(f"{GAS_URL}?action=get_pm_data&client_code={code}", headers=headers, allow_redirects=True)
    if response.status_code == 200:
        return response.json()
    return None

with st.spinner("í”„ë¡œì íŠ¸ ì›ì¥ ë°ì´í„°ë¥¼ ë™ê¸°í™” ì¤‘ì…ë‹ˆë‹¤... (ì‹¤ì‹œê°„ ë¡œë“œ ì¤‘)"):
    pm_data = get_pm_data(client_code)

if not pm_data:
    st.error("ë°ì´í„° ì„œë²„ì™€ í†µì‹ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

# --- 3. UI/UX ë ˆì´ì•„ì›ƒ ë¶„í•  ---
with st.sidebar:
    st.title("ğŸ“Š í”„ë¡œì íŠ¸ ëŒ€ì‹œë³´ë“œ")
    st.markdown("---")
    st.info(f"**ì§„í–‰ ê³ ê°ì‚¬:** [{client_code}]")
    st.success("**ë‹´ë‹¹ PM:** ë©”ì´ì»¤ëª¬ AI ì „ë‹´ PM")
    
    st.markdown("### ğŸ“Œ ì‹œìŠ¤í…œ ê¸°ëŠ¥")
    st.markdown("- ì‹¤ì‹œê°„ ì¼ì • íŠ¸ë˜í‚¹\n- ìµœì‹  ë¦¬í¬íŠ¸ ìš”ì•½\n- ë¶€í’ˆ/ë„ë©´ ì›ì¥ ê²€ìƒ‰")
    st.markdown("---")
    st.markdown("### ğŸ› ï¸ ê´€ë¦¬ì ë””ë²„ê·¸ íˆ´")
    show_raw_data = st.toggle("í˜„ì¬ ìˆ˜ì‹ ëœ DB ì›ì¥ ë³´ê¸°")
    if show_raw_data:
        st.json(pm_data)

st.title("ğŸ¤– ë©”ì´ì»¤ëª¬ ì „ë‹´ PM AI")
st.markdown("ê³ ê°ë‹˜, í™˜ì˜í•©ë‹ˆë‹¤. í”„ë¡œì íŠ¸ ì§„í–‰ ìƒí™©, ì¼ì •, ë„ë©´ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë§ì”€í•´ ì£¼ì„¸ìš”.")
st.markdown("---")

# --- 4. ë¬´ê²°ì  AI ë‘ë‡Œ ì„¸íŒ… ---
genai.configure(api_key=GOOGLE_API_KEY)

system_instruction = f"""
ë‹¹ì‹ ì€ íŒ¹ë¦¬ìŠ¤ ì œì¡° í”Œë«í¼ 'ë©”ì´ì»¤ëª¬'ì˜ 1ì¸ ìë™í™” íŒ©í† ë¦¬ë¥¼ ì§€ì›í•˜ëŠ” ë¬´ê²°ì  ì „ë‹´ AI PMì…ë‹ˆë‹¤.
í˜„ì¬ ê³ ê°ì‚¬ ì½”ë“œëŠ” [{client_code}] ì´ë©°, 'ê³ ê°ë‹˜ ì „ë‹´ PM'ì´ë¼ê³  ì •ì¤‘íˆ ì‘ëŒ€í•˜ì„¸ìš”.

[ì ˆëŒ€ ì›ì¹™: ê°•ì œ ë°ì´í„° íƒìƒ‰ ì•Œê³ ë¦¬ì¦˜]
ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µí•˜ê¸° ì „, ëŒ€ì¶© í›‘ì–´ë³´ê³  ë‹µë³€ì„ ì§€ì–´ë‚´ëŠ” í–‰ìœ„(Lazy Evaluation)ê°€ ì—„ê²©íˆ ê¸ˆì§€ë©ë‹ˆë‹¤. 
ë°˜ë“œì‹œ ì•„ë˜ ìˆœì„œëŒ€ë¡œ ì œê³µëœ JSON ë°ì´í„°ë¥¼ ë°°ì—´ 1ë²ˆë¶€í„° ëê¹Œì§€ 'ê¸€ì ë‹¨ìœ„'ë¡œ ìŠ¤ìº”í•˜ì„¸ìš”.

1. ì¼ì • ê´€ë ¨: 'schedule' ë°°ì—´ì˜ ëª¨ë“  í•­ëª© ìŠ¤ìº”.
2. ì§„í–‰ìƒí™©/ì´ìŠˆ ê´€ë ¨ (ì˜ˆ: ëª©ì—…, ì¡°ë¦½, ì„¤ê³„ìƒíƒœ ë“±): 'reports' ë°°ì—´ ë‚´ì˜ ëª¨ë“  `report_title`ê³¼ `report_summary`ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ ì •ë….
3. ë¶€í’ˆ/ë„ë©´ ê´€ë ¨: 'parts' ë°°ì—´ì˜ ëª¨ë“  í•­ëª© ìŠ¤ìº”.

ì§ˆë¬¸ì„ ë°›ìœ¼ë©´ ë°ì´í„°ì…‹ì— ì¡´ì¬í•˜ëŠ” ëª¨ë“  ì—°ê´€ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ íŒ©íŠ¸ë¥¼ í™•ì¸í•œ ë’¤ ë‹µë³€í•˜ì„¸ìš”. ì°¾ì€ ì •ë³´ëŠ” ë°˜ë“œì‹œ [ë¬¸ì„œ ë³´ê¸°](drive_link) í˜•íƒœì˜ ë§ˆí¬ë‹¤ìš´ ë§í¬ë¥¼ í¬í•¨í•˜ì„¸ìš”.

[í”„ë¡œì íŠ¸ ì›ì¥ ë°ì´í„°]
{json.dumps(pm_data, ensure_ascii=False, indent=2)}
"""

model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    system_instruction=system_instruction,
    generation_config=genai.GenerationConfig(temperature=0.1) 
)

if "chat_session" not in st.session_state:
    st.session_state.chat_session = model.start_chat(history=[])

# --- 5. ëŒ€í™” ë Œë”ë§ ---
for message in st.session_state.chat_session.history:
    role = "user" if message.role == "user" else "assistant"
    with st.chat_message(role):
        st.markdown(message.parts[0].text)

if prompt := st.chat_input("ë©”ì´ì»¤ëª¬ PMì—ê²Œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    with st.chat_message("user"):
        st.markdown(prompt)
        
    with st.chat_message("assistant"):
        with st.spinner("PMì´ ì›ì¥ ë°ì´í„°ë¥¼ ê¼¼ê¼¼íˆ ìŠ¤ìº”í•˜ì—¬ íŒ©íŠ¸ë¥¼ í™•ì¸ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                response = st.session_state.chat_session.send_message(prompt)
                st.markdown(response.text)
            except Exception as e:
                st.error(f"AI ì‘ë‹µ ì—ëŸ¬: {e}")